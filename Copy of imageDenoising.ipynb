{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of imageDenoising.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"bQ5o_lbpzF2r","colab_type":"code","cellView":"code","outputId":"005f6534-6da7-4a08-ead0-5ce07150a21a","executionInfo":{"status":"ok","timestamp":1541990711837,"user_tz":300,"elapsed":291763,"user":{"displayName":"Harshit Srivastava","photoUrl":"https://lh5.googleusercontent.com/-vutIvbnB1jA/AAAAAAAAAAI/AAAAAAAAADg/4IFdrpCWP1I/s64/photo.jpg","userId":"17927861323409553094"}},"colab":{"base_uri":"https://localhost:8080/","height":484}},"cell_type":"code","source":["#Downloading the dataset  \n","!mkdir dataset\n","%cd dataset\n","!wget https://cv.snu.ac.kr/research/VDSR/train_data.zip\n","!wget https://cv.snu.ac.kr/research/VDSR/test_data.zip\n","!unzip train_data.zip\n","!unzip test_data.zip\n","%cd .."],"execution_count":13,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘dataset’: File exists\n","/content/dataset\n","--2018-11-12 02:40:22--  https://cv.snu.ac.kr/research/VDSR/train_data.zip\n","Resolving cv.snu.ac.kr (cv.snu.ac.kr)... 147.46.116.247\n","Connecting to cv.snu.ac.kr (cv.snu.ac.kr)|147.46.116.247|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 41628740 (40M) [application/zip]\n","Saving to: ‘train_data.zip.1’\n","\n","train_data.zip.1    100%[===================>]  39.70M  4.23MB/s    in 10s     \n","\n","2018-11-12 02:40:33 (3.83 MB/s) - ‘train_data.zip.1’ saved [41628740/41628740]\n","\n","--2018-11-12 02:40:34--  https://cv.snu.ac.kr/research/VDSR/test_data.zip\n","Resolving cv.snu.ac.kr (cv.snu.ac.kr)... 147.46.116.247\n","Connecting to cv.snu.ac.kr (cv.snu.ac.kr)|147.46.116.247|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 62972123 (60M) [application/zip]\n","Saving to: ‘test_data.zip.1’\n","\n","test_data.zip.1     100%[===================>]  60.05M  4.72MB/s    in 16s     \n","\n","2018-11-12 02:40:50 (3.86 MB/s) - ‘test_data.zip.1’ saved [62972123/62972123]\n","\n","Archive:  train_data.zip\n","replace 291/000t1.bmp? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  test_data.zip\n","replace B100/101085.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: /content\n"],"name":"stdout"}]},{"metadata":{"id":"bcMgK-koyqk2","colab_type":"code","colab":{}},"cell_type":"code","source":["import glob\n","images = np.array([cv2.imread(file) for file in glob.glob(\"dataset/291/*.bmp\")])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GxL66vcGz1dd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"45bd2e5d-91da-4269-a849-8da76065e2c3","executionInfo":{"status":"ok","timestamp":1541990783730,"user_tz":300,"elapsed":360,"user":{"displayName":"Harshit Srivastava","photoUrl":"https://lh5.googleusercontent.com/-vutIvbnB1jA/AAAAAAAAAAI/AAAAAAAAADg/4IFdrpCWP1I/s64/photo.jpg","userId":"17927861323409553094"}}},"cell_type":"code","source":["images[0].shape"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(176, 215, 3)"]},"metadata":{"tags":[]},"execution_count":23}]},{"metadata":{"colab_type":"code","id":"YJn7HIf61d3g","colab":{}},"cell_type":"code","source":[" #Importing the required packages\n","from pathlib import Path\n","import random\n","import numpy as np\n","import cv2\n","import string\n","import os\n","from keras.utils import Sequence\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","from keras.models import Model\n","from keras.layers import Input, Add, PReLU, Conv2DTranspose, Concatenate, MaxPooling2D, UpSampling2D, Dropout\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint\n","from keras import backend as K\n","from keras.optimizers import Adam"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6O7OPpPPW8NQ","colab_type":"code","colab":{}},"cell_type":"code","source":["class NoisyImageGenerator(Sequence):\n","  \n","  def __init__(self, image_dir, source_noise_model, target_noise_model, batch_size=32, image_size=64):\n","\n","    self.image_paths = list(Path(image_dir).glob(\"*.jpg\"))\n","    self.source_noise_model = source_noise_model\n","    self.target_noise_model = target_noise_model\n","    self.image_num = len(self.image_paths)\n","    self.batch_size = batch_size\n","    self.image_size = image_size\n","\n","  def __len__(self):\n","\n","    return self.image_num // self.batch_size\n","\n","  def __getitem__(self, idx):\n","\n","    batch_size = self.batch_size\n","    image_size = self.image_size\n","    x = np.zeros((batch_size, image_size, image_size, 3), dtype=np.uint8)\n","    y = np.zeros((batch_size, image_size, image_size, 3), dtype=np.uint8)\n","    sample_id = 0\n","\n","    while True:\n","      \n","      image_path = random.choice(self.image_paths)\n","      image = cv2.imread(str(image_path))\n","      h, w, _ = image.shape\n","\n","      if h >= image_size and w >= image_size:\n","          h, w, _ = image.shape\n","          i = np.random.randint(h - image_size + 1)\n","          j = np.random.randint(w - image_size + 1)\n","          clean_patch = image[i:i + image_size, j:j + image_size]\n","          x[sample_id] = self.source_noise_model(clean_patch)\n","          y[sample_id] = self.target_noise_model(clean_patch)\n","\n","          sample_id += 1\n","\n","          if sample_id == batch_size:\n","              return x, y\n","\n","\n","class ValGenerator(Sequence):\n","  \n","    def __init__(self, image_dir, val_noise_model):\n","      \n","        image_paths = list(Path(image_dir).glob(\"*.*\"))\n","        self.image_num = len(image_paths)\n","        self.data = []\n","\n","        for image_path in image_paths:\n","            y = cv2.imread(str(image_path))\n","            h, w, _ = y.shape\n","            y = y[:(h // 16) * 16, :(w // 16) * 16]  # for stride (maximum 16)\n","            x = val_noise_model(y)\n","            self.data.append([np.expand_dims(x, axis=0), np.expand_dims(y, axis=0)])\n","\n","    def __len__(self):\n","        return self.image_num\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LRS9wOWPXYwY","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_noise_model(noise_type=\"gaussian,0,50\"):\n","  \n","    tokens = noise_type.split(sep=\",\")\n","\n","    if tokens[0] == \"gaussian\":\n","        min_stddev = int(tokens[1])\n","        max_stddev = int(tokens[2])\n","\n","        def gaussian_noise(img):\n","            noise_img = img.astype(np.float)\n","            stddev = np.random.uniform(min_stddev, max_stddev)\n","            noise = np.random.randn(*img.shape) * stddev\n","            noise_img += noise\n","            noise_img = np.clip(noise_img, 0, 255).astype(np.uint8)\n","            return noise_img\n","          \n","        return gaussian_noise\n","      \n","    elif tokens[0] == \"clean\":\n","        return lambda img: img\n","      \n","    elif tokens[0] == \"text\":\n","      \n","        min_occupancy = int(tokens[1])\n","        max_occupancy = int(tokens[2])\n","\n","        def add_text(img):\n","          \n","            img = img.copy()\n","            h, w, _ = img.shape\n","            font = cv2.FONT_HERSHEY_SIMPLEX\n","            img_for_cnt = np.zeros((h, w), np.uint8)\n","            occupancy = np.random.uniform(min_occupancy, max_occupancy)\n","\n","            while True:\n","                n = random.randint(5, 10)\n","                random_str = ''.join([random.choice(string.ascii_letters + string.digits) for i in range(n)])\n","                font_scale = np.random.uniform(0.5, 1)\n","                thickness = random.randint(1, 3)\n","                (fw, fh), baseline = cv2.getTextSize(random_str, font, font_scale, thickness)\n","                x = random.randint(0, max(0, w - 1 - fw))\n","                y = random.randint(fh, h - 1 - baseline)\n","                color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n","                cv2.putText(img, random_str, (x, y), font, font_scale, color, thickness)\n","                cv2.putText(img_for_cnt, random_str, (x, y), font, font_scale, 255, thickness)\n","\n","                if (img_for_cnt > 0).sum() > h * w * occupancy / 100:\n","                    break\n","            return img\n","          \n","        return add_text\n","      \n","      \n","    elif tokens[0] == \"impulse\":\n","      \n","        min_occupancy = int(tokens[1])\n","        max_occupancy = int(tokens[2])\n","\n","        def add_impulse_noise(img):\n","            occupancy = np.random.uniform(min_occupancy, max_occupancy)\n","            mask = np.random.binomial(size=img.shape, n=1, p=occupancy / 100)\n","            noise = np.random.randint(256, size=img.shape)\n","            img = img * (1 - mask) + noise * mask\n","            return img.astype(np.uint8)\n","        return add_impulse_noise\n","    else:\n","        raise ValueError(\"noise_type should be 'gaussian', 'clean', 'text', or 'impulse'\")\n","\n","\n","#def main():\n","#\n","#    image_size = 256\n","#    noise_model = get_noise_model(\"text,0,10\")\n","#\n","#    while True:\n","#        \n","#        image = np.ones((image_size, image_size, 3), dtype=np.uint8) * 128\n","#        noisy_image = noise_model(image)\n","#        plt.imshow(noisy_image)\n","#        plt.show()\n","#        break\n","#        key = cv2.waitKey(-1)\n","#\n","#        # \"q\": quit\n","#        if key == 113:\n","#            return 0\n","#\n","#main()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Sg5qeXlSV2Fw","colab_type":"code","colab":{}},"cell_type":"code","source":["class L0Loss:\n","  \n","  def __init__(self):\n","    \n","    self.gamma = K.variable(2.)\n","\n","  def __call__(self):\n","    \n","    def calc_loss(y_true, y_pred):\n","        loss = K.pow(K.abs(y_true - y_pred) + 1e-8, self.gamma)\n","        return loss\n","    return calc_loss\n","\n","\n","class UpdateAnnealingParameter(Callback):\n","  \n","    def __init__(self, gamma, nb_epochs, verbose=0):\n","      \n","      super(UpdateAnnealingParameter, self).__init__()\n","      self.gamma = gamma\n","      self.nb_epochs = nb_epochs\n","      self.verbose = verbose\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","      \n","      new_gamma = 2.0 * (self.nb_epochs - epoch) / self.nb_epochs\n","      K.set_value(self.gamma, new_gamma)\n","\n","      if self.verbose > 0:\n","          print('\\nEpoch %05d: UpdateAnnealingParameter reducing gamma to %s.' % (epoch + 1, new_gamma))\n","\n","\n","def tf_log10(x):\n","  \n","  numerator = tf.log(x)\n","  denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n","  return numerator / denominator\n","\n","\n","def PSNR(y_true, y_pred):\n","  \n","  max_pixel = 255.0\n","  y_pred = K.clip(y_pred, 0.0, 255.0)\n","  return 10.0 * tf_log10((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true))))\n","\n","\n","def get_model(model_name=\"srresnet\"):\n","  \n","  if model_name == \"srresnet\":\n","      return get_srresnet_model()\n","  elif model_name == \"unet\":\n","      return get_unet_model(out_ch=3)\n","  else:\n","      raise ValueError(\"model_name should be 'srresnet'or 'unet'\")\n","\n","\n","# SRResNet\n","def get_srresnet_model(input_channel_num=3, feature_dim=64, resunit_num=16):\n","    def _residual_block(inputs):\n","        x = Conv2D(feature_dim, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")(inputs)\n","        x = BatchNormalization()(x)\n","        x = PReLU(shared_axes=[1, 2])(x)\n","        x = Conv2D(feature_dim, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")(x)\n","        x = BatchNormalization()(x)\n","        m = Add()([x, inputs])\n","\n","        return m\n","\n","    inputs = Input(shape=(None, None, input_channel_num))\n","    x = Conv2D(feature_dim, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")(inputs)\n","    x = PReLU(shared_axes=[1, 2])(x)\n","    x0 = x\n","\n","    for i in range(resunit_num):\n","        x = _residual_block(x)\n","\n","    x = Conv2D(feature_dim, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")(x)\n","    x = BatchNormalization()(x)\n","    x = Add()([x, x0])\n","    x = Conv2D(input_channel_num, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")(x)\n","    model = Model(inputs=inputs, outputs=x)\n","\n","    return model\n","\n","\n","def get_unet_model(input_channel_num=3, out_ch=3, start_ch=64, depth=4, inc_rate=2., activation='relu',\n","         dropout=0.5, batchnorm=False, maxpool=True, upconv=True, residual=False):\n","    def _conv_block(m, dim, acti, bn, res, do=0):\n","        n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n","        n = BatchNormalization()(n) if bn else n\n","        n = Dropout(do)(n) if do else n\n","        n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n","        n = BatchNormalization()(n) if bn else n\n","\n","        return Concatenate()([m, n]) if res else n\n","\n","    def _level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n","        if depth > 0:\n","            n = _conv_block(m, dim, acti, bn, res)\n","            m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n","            m = _level_block(m, int(inc * dim), depth - 1, inc, acti, do, bn, mp, up, res)\n","            if up:\n","                m = UpSampling2D()(m)\n","                m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n","            else:\n","                m = Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)\n","            n = Concatenate()([n, m])\n","            m = _conv_block(n, dim, acti, bn, res)\n","        else:\n","            m = _conv_block(m, dim, acti, bn, res, do)\n","\n","        return m\n","\n","    i = Input(shape=(None, None, input_channel_num))\n","    o = _level_block(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)\n","    o = Conv2D(out_ch, 1)(o)\n","    model = Model(inputs=i, outputs=o)\n","\n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2FlsbD_PTuuh","colab_type":"code","outputId":"ac3ba573-8c62-4ebf-e974-243f9f490597","executionInfo":{"status":"ok","timestamp":1541967214707,"user_tz":300,"elapsed":16163060,"user":{"displayName":"Harshit Srivastava","photoUrl":"https://lh5.googleusercontent.com/-vutIvbnB1jA/AAAAAAAAAAI/AAAAAAAAADg/4IFdrpCWP1I/s64/photo.jpg","userId":"17927861323409553094"}},"colab":{"base_uri":"https://localhost:8080/","height":3472}},"cell_type":"code","source":["class Schedule:\n","  \n","  def __init__(self, nb_epochs, initial_lr):\n","\n","    self.epochs = nb_epochs\n","    self.initial_lr = initial_lr\n","\n","  def __call__(self, epoch_idx):\n","\n","    if epoch_idx < self.epochs * 0.25:\n","        return self.initial_lr\n","    elif epoch_idx < self.epochs * 0.50:\n","        return self.initial_lr * 0.5\n","    elif epoch_idx < self.epochs * 0.75:\n","        return self.initial_lr * 0.25\n","    return self.initial_lr * 0.125\n","\n","def train():\n","  \n","  image_dir = \"dataset/291\"\n","  test_dir =  \"dataset/Set14\"\n","  image_size = 64\n","  batch_size = 8\n","  nb_epochs = 50\n","  lr = 0.001\n","  steps = 1000\n","  loss_type = \"mse\"\n","  os.path.dirname(os.path.abspath(\"__file__\"))\n","  output_path = Path(\"__file__\").resolve().parent.joinpath(\"output\")\n","  model = get_model(\"srresnet\")\n","  opt = Adam(lr=lr)\n","  callbacks = []\n","\n","  if loss_type == \"l0\":\n","      l0 = L0Loss()\n","      callbacks.append(UpdateAnnealingParameter(l0.gamma, nb_epochs, verbose=1))\n","      loss_type = l0()\n","\n","  model.compile(optimizer=opt, loss=loss_type, metrics=[PSNR])\n","  source_noise_model = get_noise_model(\"gaussian,0,50\")\n","  target_noise_model = get_noise_model( \"gaussian,0,50\")\n","  val_noise_model = get_noise_model(\"gaussian,25,25\")\n","  generator = NoisyImageGenerator(image_dir, source_noise_model, target_noise_model, batch_size=batch_size,\n","                                  image_size=image_size)\n","  val_generator = ValGenerator(test_dir, val_noise_model)\n","  output_path.mkdir(parents=True, exist_ok=True)\n","  callbacks.append(LearningRateScheduler(schedule=Schedule(nb_epochs, lr)))\n","  callbacks.append(ModelCheckpoint(str(output_path) + \"/weights.{epoch:03d}-{val_loss:.3f}-{val_PSNR:.5f}.hdf5\",\n","                                   monitor=\"val_PSNR\",\n","                                   verbose=1,\n","                                   mode=\"max\",\n","                                   save_best_only=True))\n","\n","  history = model.fit_generator(generator=generator,\n","                             steps_per_epoch=steps,\n","                             epochs=nb_epochs,\n","                             validation_data=val_generator,\n","                             verbose=1,\n","                             callbacks=callbacks)\n","\n","  np.savez(str(output_path.joinpath(\"history.npz\")), history=history.history)\n","  \n","  return history\n","\n","\n","history = train()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1000/1000 [==============================] - 333s 333ms/step - loss: 1011.5027 - PSNR: 18.5553 - val_loss: 105.8168 - val_PSNR: 28.2706\n","\n","Epoch 00001: val_PSNR improved from -inf to 28.27057, saving model to /content/output/weights.001-105.817-28.27057.hdf5\n","Epoch 2/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 816.7848 - PSNR: 19.1950 - val_loss: 108.8332 - val_PSNR: 28.1892\n","\n","Epoch 00002: val_PSNR did not improve from 28.27057\n","Epoch 3/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 796.3234 - PSNR: 19.2987 - val_loss: 109.7477 - val_PSNR: 28.0474\n","\n","Epoch 00003: val_PSNR did not improve from 28.27057\n","Epoch 4/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 789.7281 - PSNR: 19.3356 - val_loss: 117.0843 - val_PSNR: 27.6624\n","\n","Epoch 00004: val_PSNR did not improve from 28.27057\n","Epoch 5/50\n","1000/1000 [==============================] - 323s 323ms/step - loss: 801.6330 - PSNR: 19.2992 - val_loss: 90.4061 - val_PSNR: 29.0002\n","\n","Epoch 00005: val_PSNR improved from 28.27057 to 29.00016, saving model to /content/output/weights.005-90.406-29.00016.hdf5\n","Epoch 6/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 794.4554 - PSNR: 19.3119 - val_loss: 89.2825 - val_PSNR: 29.0771\n","\n","Epoch 00006: val_PSNR improved from 29.00016 to 29.07708, saving model to /content/output/weights.006-89.282-29.07708.hdf5\n","Epoch 7/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 792.5685 - PSNR: 19.3239 - val_loss: 90.9335 - val_PSNR: 29.0206\n","\n","Epoch 00007: val_PSNR did not improve from 29.07708\n","Epoch 8/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 795.5618 - PSNR: 19.3080 - val_loss: 88.0722 - val_PSNR: 29.1452\n","\n","Epoch 00008: val_PSNR improved from 29.07708 to 29.14523, saving model to /content/output/weights.008-88.072-29.14523.hdf5\n","Epoch 9/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 802.0766 - PSNR: 19.2692 - val_loss: 88.2382 - val_PSNR: 29.1399\n","\n","Epoch 00009: val_PSNR did not improve from 29.14523\n","Epoch 10/50\n","1000/1000 [==============================] - 323s 323ms/step - loss: 786.8822 - PSNR: 19.3681 - val_loss: 81.3959 - val_PSNR: 29.4766\n","\n","Epoch 00010: val_PSNR improved from 29.14523 to 29.47664, saving model to /content/output/weights.010-81.396-29.47664.hdf5\n","Epoch 11/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 791.4144 - PSNR: 19.3297 - val_loss: 99.8354 - val_PSNR: 28.5778\n","\n","Epoch 00011: val_PSNR did not improve from 29.47664\n","Epoch 12/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 779.9115 - PSNR: 19.4000 - val_loss: 82.1668 - val_PSNR: 29.4779\n","\n","Epoch 00012: val_PSNR improved from 29.47664 to 29.47794, saving model to /content/output/weights.012-82.167-29.47794.hdf5\n","Epoch 13/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 787.6135 - PSNR: 19.3694 - val_loss: 86.7994 - val_PSNR: 29.1799\n","\n","Epoch 00013: val_PSNR did not improve from 29.47794\n","Epoch 14/50\n","1000/1000 [==============================] - 323s 323ms/step - loss: 791.4188 - PSNR: 19.3311 - val_loss: 81.0837 - val_PSNR: 29.5402\n","\n","Epoch 00014: val_PSNR improved from 29.47794 to 29.54024, saving model to /content/output/weights.014-81.084-29.54024.hdf5\n","Epoch 15/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 784.5006 - PSNR: 19.3816 - val_loss: 85.1784 - val_PSNR: 29.3167\n","\n","Epoch 00015: val_PSNR did not improve from 29.54024\n","Epoch 16/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 783.7832 - PSNR: 19.3801 - val_loss: 80.2531 - val_PSNR: 29.5649\n","\n","Epoch 00016: val_PSNR improved from 29.54024 to 29.56492, saving model to /content/output/weights.016-80.253-29.56492.hdf5\n","Epoch 17/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 783.7299 - PSNR: 19.4052 - val_loss: 85.1461 - val_PSNR: 29.3762\n","\n","Epoch 00017: val_PSNR did not improve from 29.56492\n","Epoch 18/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 776.4525 - PSNR: 19.4256 - val_loss: 77.2612 - val_PSNR: 29.7511\n","\n","Epoch 00018: val_PSNR improved from 29.56492 to 29.75109, saving model to /content/output/weights.018-77.261-29.75109.hdf5\n","Epoch 19/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 788.8171 - PSNR: 19.3542 - val_loss: 84.0790 - val_PSNR: 29.3794\n","\n","Epoch 00019: val_PSNR did not improve from 29.75109\n","Epoch 20/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 798.4621 - PSNR: 19.2908 - val_loss: 78.5319 - val_PSNR: 29.6668\n","\n","Epoch 00020: val_PSNR did not improve from 29.75109\n","Epoch 21/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 783.4798 - PSNR: 19.3959 - val_loss: 83.6529 - val_PSNR: 29.3778\n","\n","Epoch 00021: val_PSNR did not improve from 29.75109\n","Epoch 22/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 784.1495 - PSNR: 19.3795 - val_loss: 76.7822 - val_PSNR: 29.8018\n","\n","Epoch 00022: val_PSNR improved from 29.75109 to 29.80184, saving model to /content/output/weights.022-76.782-29.80184.hdf5\n","Epoch 23/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 788.1894 - PSNR: 19.3610 - val_loss: 82.6962 - val_PSNR: 29.4297\n","\n","Epoch 00023: val_PSNR did not improve from 29.80184\n","Epoch 24/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 781.2197 - PSNR: 19.3920 - val_loss: 81.6278 - val_PSNR: 29.5006\n","\n","Epoch 00024: val_PSNR did not improve from 29.80184\n","Epoch 25/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 778.5885 - PSNR: 19.4248 - val_loss: 81.7688 - val_PSNR: 29.4689\n","\n","Epoch 00025: val_PSNR did not improve from 29.80184\n","Epoch 26/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 792.3239 - PSNR: 19.3421 - val_loss: 83.5534 - val_PSNR: 29.4165\n","\n","Epoch 00026: val_PSNR did not improve from 29.80184\n","Epoch 27/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 777.1257 - PSNR: 19.4160 - val_loss: 79.7785 - val_PSNR: 29.6154\n","\n","Epoch 00027: val_PSNR did not improve from 29.80184\n","Epoch 28/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 795.1052 - PSNR: 19.3199 - val_loss: 79.0878 - val_PSNR: 29.6635\n","\n","Epoch 00028: val_PSNR did not improve from 29.80184\n","Epoch 29/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 784.7063 - PSNR: 19.3942 - val_loss: 79.9513 - val_PSNR: 29.6133\n","\n","Epoch 00029: val_PSNR did not improve from 29.80184\n","Epoch 30/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 777.2647 - PSNR: 19.4143 - val_loss: 83.6746 - val_PSNR: 29.3937\n","\n","Epoch 00030: val_PSNR did not improve from 29.80184\n","Epoch 31/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 774.0667 - PSNR: 19.4379 - val_loss: 80.5285 - val_PSNR: 29.5836\n","\n","Epoch 00031: val_PSNR did not improve from 29.80184\n","Epoch 32/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 781.1096 - PSNR: 19.3939 - val_loss: 78.4479 - val_PSNR: 29.7129\n","\n","Epoch 00032: val_PSNR did not improve from 29.80184\n","Epoch 33/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 783.5006 - PSNR: 19.3844 - val_loss: 80.1097 - val_PSNR: 29.6060\n","\n","Epoch 00033: val_PSNR did not improve from 29.80184\n","Epoch 34/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 784.9947 - PSNR: 19.3833 - val_loss: 76.0847 - val_PSNR: 29.8419\n","\n","Epoch 00034: val_PSNR improved from 29.80184 to 29.84189, saving model to /content/output/weights.034-76.085-29.84189.hdf5\n","Epoch 35/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 791.5218 - PSNR: 19.3392 - val_loss: 80.2033 - val_PSNR: 29.6127\n","\n","Epoch 00035: val_PSNR did not improve from 29.84189\n","Epoch 36/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 784.1722 - PSNR: 19.3896 - val_loss: 80.0057 - val_PSNR: 29.6178\n","\n","Epoch 00036: val_PSNR did not improve from 29.84189\n","Epoch 37/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 776.4575 - PSNR: 19.4178 - val_loss: 80.7341 - val_PSNR: 29.5277\n","\n","Epoch 00037: val_PSNR did not improve from 29.84189\n","Epoch 38/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 780.4741 - PSNR: 19.4019 - val_loss: 77.7184 - val_PSNR: 29.7381\n","\n","Epoch 00038: val_PSNR did not improve from 29.84189\n","Epoch 39/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 775.6112 - PSNR: 19.4060 - val_loss: 79.9351 - val_PSNR: 29.6286\n","\n","Epoch 00039: val_PSNR did not improve from 29.84189\n","Epoch 40/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 790.5263 - PSNR: 19.3460 - val_loss: 78.8680 - val_PSNR: 29.6749\n","\n","Epoch 00040: val_PSNR did not improve from 29.84189\n","Epoch 41/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 781.8659 - PSNR: 19.3980 - val_loss: 77.5539 - val_PSNR: 29.7531\n","\n","Epoch 00041: val_PSNR did not improve from 29.84189\n","Epoch 42/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 782.1055 - PSNR: 19.3979 - val_loss: 78.8225 - val_PSNR: 29.6919\n","\n","Epoch 00042: val_PSNR did not improve from 29.84189\n","Epoch 43/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 776.0894 - PSNR: 19.4153 - val_loss: 80.7778 - val_PSNR: 29.5539\n","\n","Epoch 00043: val_PSNR did not improve from 29.84189\n","Epoch 44/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 780.7452 - PSNR: 19.4130 - val_loss: 78.4478 - val_PSNR: 29.7162\n","\n","Epoch 00044: val_PSNR did not improve from 29.84189\n","Epoch 45/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 791.2283 - PSNR: 19.3465 - val_loss: 78.7324 - val_PSNR: 29.6795\n","\n","Epoch 00045: val_PSNR did not improve from 29.84189\n","Epoch 46/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 784.8680 - PSNR: 19.3794 - val_loss: 80.4322 - val_PSNR: 29.5845\n","\n","Epoch 00046: val_PSNR did not improve from 29.84189\n","Epoch 47/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 777.2051 - PSNR: 19.4204 - val_loss: 77.3504 - val_PSNR: 29.7703\n","\n","Epoch 00047: val_PSNR did not improve from 29.84189\n","Epoch 48/50\n","1000/1000 [==============================] - 321s 321ms/step - loss: 776.5367 - PSNR: 19.4145 - val_loss: 79.2358 - val_PSNR: 29.6587\n","\n","Epoch 00048: val_PSNR did not improve from 29.84189\n","Epoch 49/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 777.8280 - PSNR: 19.4188 - val_loss: 79.2334 - val_PSNR: 29.6611\n","\n","Epoch 00049: val_PSNR did not improve from 29.84189\n","Epoch 50/50\n","1000/1000 [==============================] - 322s 322ms/step - loss: 782.7193 - PSNR: 19.3875 - val_loss: 77.8042 - val_PSNR: 29.7372\n","\n","Epoch 00050: val_PSNR did not improve from 29.84189\n"],"name":"stdout"}]},{"metadata":{"id":"ZmgKWjbNHa1G","colab_type":"code","outputId":"a4980a6d-72e7-4cd4-84c8-f95da091add1","executionInfo":{"status":"ok","timestamp":1541967216822,"user_tz":300,"elapsed":1688,"user":{"displayName":"Harshit Srivastava","photoUrl":"https://lh5.googleusercontent.com/-vutIvbnB1jA/AAAAAAAAAAI/AAAAAAAAADg/4IFdrpCWP1I/s64/photo.jpg","userId":"17927861323409553094"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["history_dict = history.history\n","history_dict.keys()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['val_loss', 'val_PSNR', 'loss', 'PSNR', 'lr'])"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"_uqow4qVcM-I","colab_type":"code","outputId":"0ff63fac-367d-47c8-fc88-4d57134da702","executionInfo":{"status":"ok","timestamp":1541967219111,"user_tz":300,"elapsed":541,"user":{"displayName":"Harshit Srivastava","photoUrl":"https://lh5.googleusercontent.com/-vutIvbnB1jA/AAAAAAAAAAI/AAAAAAAAADg/4IFdrpCWP1I/s64/photo.jpg","userId":"17927861323409553094"}},"colab":{"base_uri":"https://localhost:8080/","height":376}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","acc = history.history['PSNR']\n","val_acc = history.history['val_PSNR']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","# \"bo\" is for \"blue dot\"\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","# b is for \"solid blue line\"\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfgAAAFnCAYAAABKGFvpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nImJACngREREDUsCLiIgYkAJeRETEgP4fSD8C+lIw+oMAAAAASUVORK5CYII=\n","text/plain":["<matplotlib.figure.Figure at 0x7f28cbda1d30>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"AHZ93jAf-qGR","colab_type":"code","outputId":"760c319d-fe9b-4d8a-8246-80c5050448f1","executionInfo":{"status":"ok","timestamp":1541911767914,"user_tz":300,"elapsed":35565,"user":{"displayName":"Harshit Srivastava","photoUrl":"https://lh5.googleusercontent.com/-vutIvbnB1jA/AAAAAAAAAAI/AAAAAAAAADg/4IFdrpCWP1I/s64/photo.jpg","userId":"17927861323409553094"}},"colab":{"base_uri":"https://localhost:8080/","height":2384,"output_embedded_package_id":"1FQeF5cMbJM5J87YBWMH2QgGP25F5b6AQ"}},"cell_type":"code","source":["#Testing the model - \n","#Testing the model - \n","\n","def getImage(image):\n","    image = np.clip(image, 0, 255)\n","    return image.astype(dtype=np.uint8)\n","\n","\n","def test():\n","\n","    image_dir = \"dataset/Set14\"\n","    weight_file = \"/content/output/weights.005-96.168-28.71974.hdf5\"\n","    val_noise_model = get_noise_model(\"gaussian,25,25\")\n","    model = get_model(\"srresnet\")\n","    model.load_weights(weight_file)\n","\n","    #if args.output_dir:\n","    #    output_dir = Path(args.output_dir)\n","    #    output_dir.mkdir(parents=True, exist_ok=True)\n","\n","    image_paths = list(Path(image_dir).glob(\"*.*\"))\n","\n","    for image_path in image_paths:\n","        image = cv2.imread(str(image_path))\n","        h, w, _ = image.shape\n","        image = image[:(h // 16) * 16, :(w // 16) * 16]  # for stride (maximum 16)\n","        h, w, _ = image.shape\n","\n","        out_image = np.zeros((h, w * 3, 3), dtype=np.uint8)\n","        noise_image = val_noise_model(image)\n","        pred = model.predict(np.expand_dims(noise_image, 0))\n","        denoised_image = getImage(pred[0])\n","#         out_image[:, :w] = image\n","#         out_image[:, w:w * 2] = noise_image\n","#         out_image[:, w * 2:] = denoised_image\n","\n","        #if args.output_dir:\n","        #    cv2.imwrite(str(output_dir.joinpath(image_path.name))[:-4] + \".png\", out_image)\n","        #else:\n","        plt.subplot(1, 3, 1)\n","        plt.imshow(image)\n","        plt.title(\"Image\")\n","        \n","        plt.subplot(1, 3, 2)\n","        plt.imshow(noise_image)\n","        plt.title(\"Noisy Image\")\n","        \n","        plt.subplot(1, 3, 3)\n","        plt.imshow(denoised_image)\n","        plt.title(\"De-noised Image\")\n","        \n","        plt.show()\n","        key = cv2.waitKey(-1)\n","        # \"q\": quit\n","        if key == 113:\n","            return 0\n","\n","\n","test()"],"execution_count":0},{"metadata":{"id":"lfQireQpahCX","colab_type":"code","colab":{}},"cell_type":"code","source":["   "],"execution_count":0,"outputs":[]}]}