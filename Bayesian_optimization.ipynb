{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RqjkDNxAJYv9",
    "outputId": "7de5cb6e-b058-4ea9-b6e6-a8e56ca2ed61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshitsrivastava/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing the required packages\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Add, PReLU, Conv2DTranspose, Concatenate, MaxPooling2D, UpSampling2D, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.optimizers import *\n",
    "from keras.utils import Sequence\n",
    "# Using Keras Model in Scikit Learn\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# include below until https://github.com/scikit-optimize/scikit-optimize/issues/718 is resolved\n",
    "class BayesSearchCV(BayesSearchCV):\n",
    "    def _run_search(self, x): raise BaseException('Use newer skopt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10951
    },
    "colab_type": "code",
    "id": "RNnPUdlRJYwE",
    "outputId": "baeec634-f7c2-4d58-a2d1-c64d23a1c3ec"
   },
   "outputs": [],
   "source": [
    "# # When running on colab, run below commands\n",
    "# !mkdir dataset\n",
    "# %cd dataset\n",
    "# !wget https://cv.snu.ac.kr/research/VDSR/train_data.zip\n",
    "# !wget https://cv.snu.ac.kr/research/VDSR/test_data.zip\n",
    "# !unzip train_data.zip\n",
    "# !unzip test_data.zip\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkWdB-4kJYwG"
   },
   "outputs": [],
   "source": [
    "def get_noise_model(noise_type=\"gaussian,0,50\"):\n",
    "    tokens = noise_type.split(sep=\",\")\n",
    "\n",
    "    if tokens[0] == \"gaussian\":\n",
    "        min_stddev = int(tokens[1])\n",
    "        max_stddev = int(tokens[2])\n",
    "\n",
    "        def gaussian_noise(img):\n",
    "            noise_img = img.astype(np.float)\n",
    "            stddev = np.random.uniform(min_stddev, max_stddev)\n",
    "            noise = np.random.randn(*img.shape) * stddev\n",
    "            noise_img += noise\n",
    "            noise_img = np.clip(noise_img, 0, 255).astype(np.uint8)\n",
    "            return noise_img\n",
    "\n",
    "        return gaussian_noise\n",
    "\n",
    "    elif tokens[0] == \"clean\":\n",
    "        return lambda img: img\n",
    "\n",
    "    elif tokens[0] == \"text\":\n",
    "\n",
    "        min_occupancy = int(tokens[1])\n",
    "        max_occupancy = int(tokens[2])\n",
    "\n",
    "        def add_text(img):\n",
    "\n",
    "            img = img.copy()\n",
    "            h, w, _ = img.shape\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            img_for_cnt = np.zeros((h, w), np.uint8)\n",
    "            occupancy = np.random.uniform(min_occupancy, max_occupancy)\n",
    "\n",
    "            while True:\n",
    "                n = random.randint(5, 10)\n",
    "                random_str = ''.join([random.choice(string.ascii_letters + string.digits) for i in range(n)])\n",
    "                font_scale = np.random.uniform(0.5, 1)\n",
    "                thickness = random.randint(1, 3)\n",
    "                (fw, fh), baseline = cv2.getTextSize(random_str, font, font_scale, thickness)\n",
    "                x = random.randint(0, max(0, w - 1 - fw))\n",
    "                y = random.randint(fh, h - 1 - baseline)\n",
    "                color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "                cv2.putText(img, random_str, (x, y), font, font_scale, color, thickness)\n",
    "                cv2.putText(img_for_cnt, random_str, (x, y), font, font_scale, 255, thickness)\n",
    "\n",
    "                if (img_for_cnt > 0).sum() > h * w * occupancy / 100:\n",
    "                    break\n",
    "            return img\n",
    "\n",
    "        return add_text\n",
    "\n",
    "\n",
    "    elif tokens[0] == \"impulse\":\n",
    "\n",
    "        min_occupancy = int(tokens[1])\n",
    "        max_occupancy = int(tokens[2])\n",
    "\n",
    "        def add_impulse_noise(img):\n",
    "            occupancy = np.random.uniform(min_occupancy, max_occupancy)\n",
    "            mask = np.random.binomial(size=img.shape, n=1, p=occupancy / 100)\n",
    "            noise = np.random.randint(256, size=img.shape)\n",
    "            img = img * (1 - mask) + noise * mask\n",
    "            return img.astype(np.uint8)\n",
    "        return add_impulse_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ovYc7MH-JYwJ"
   },
   "outputs": [],
   "source": [
    "class NoisyImageGenerator(Sequence):\n",
    "  \n",
    "  def __init__(self, image_dir, source_noise_model, target_noise_model, batch_size=10000, image_size=128):\n",
    "\n",
    "    self.image_paths = list(Path(image_dir).glob(\"*.jpg\"))\n",
    "    self.source_noise_model = source_noise_model\n",
    "    self.target_noise_model = target_noise_model\n",
    "    self.image_num = len(self.image_paths)\n",
    "    self.batch_size = batch_size\n",
    "    self.image_size = image_size\n",
    "\n",
    "  def __len__(self):\n",
    "\n",
    "    return self.image_num // self.batch_size\n",
    "\n",
    "  def __getitem__(self):\n",
    "\n",
    "    batch_size = self.batch_size\n",
    "    image_size = self.image_size\n",
    "    x = np.zeros((batch_size, image_size, image_size, 3), dtype=np.uint8)\n",
    "    y = np.zeros((batch_size, image_size, image_size, 3), dtype=np.uint8)\n",
    "    sample_id = 0\n",
    "\n",
    "    while True:\n",
    "      \n",
    "      image_path = random.choice(self.image_paths)\n",
    "      image = cv2.imread(str(image_path))\n",
    "      h, w, _ = image.shape\n",
    "\n",
    "      if h >= image_size and w >= image_size:\n",
    "          h, w, _ = image.shape\n",
    "          i = np.random.randint(h - image_size + 1)\n",
    "          j = np.random.randint(w - image_size + 1)\n",
    "          clean_patch = image[i:i + image_size, j:j + image_size]\n",
    "          x[sample_id] = self.source_noise_model(clean_patch)\n",
    "          y[sample_id] = self.target_noise_model(clean_patch)\n",
    "\n",
    "          sample_id += 1\n",
    "\n",
    "          if sample_id == batch_size:\n",
    "              return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-wGPxtoeJYwL"
   },
   "outputs": [],
   "source": [
    "class Generator(Sequence):\n",
    "    def __init__(self, image_dir, val_noise_model):\n",
    "\n",
    "        image_paths = list(Path(image_dir).glob(\"*.*\"))\n",
    "        self.image_num = len(image_paths)\n",
    "        self.data = []\n",
    "\n",
    "        for image_path in image_paths:\n",
    "            y = cv2.imread(str(image_path))\n",
    "            h, w, _ = y.shape\n",
    "            y = y[:(h // 16) * 16, :(w // 16) * 16]  # for stride (maximum 16)\n",
    "            x = val_noise_model(y)\n",
    "            self.data.append(x)\n",
    "            #print (x.shape)\n",
    "            #print(y.shape)\n",
    "            #self.data.append([np.expand_dims(x, axis=0), np.expand_dims(y, axis=0)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJbjChdOJYwN"
   },
   "outputs": [],
   "source": [
    "source_noise_model = get_noise_model(\"text,0,50\")\n",
    "target_noise_model = get_noise_model( \"text,0,0\")\n",
    "val_noise_model = get_noise_model(\"text,0,50\")\n",
    "\n",
    "image_dir = \"dataset/291\"\n",
    "test_dir =  \"dataset/Set14\"\n",
    "\n",
    "# batch_size = 4\n",
    "# learning_rate = 0.003\n",
    "\n",
    "# noisy_generator = NoisyImageGenerator(image_dir, source_noise_model, target_noise_model, batch_size=batch_size,\n",
    "#                               image_size=64)\n",
    "# val_generator = ValGenerator(test_dir, val_noise_model)\n",
    "x, y = np.array(NoisyImageGenerator(image_dir, source_noise_model, target_noise_model).__getitem__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QpyJ9dcEJYwQ"
   },
   "outputs": [],
   "source": [
    "def tf_log10(x):\n",
    "    numerator = tf.log(x)\n",
    "    denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "def PSNR(y_true, y_pred):\n",
    "    max_pixel = 255.0\n",
    "    y_pred = K.clip(y_pred, 0.0, 255.0)\n",
    "    return 10.0 * tf_log10((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xqw3GI3CJYwT"
   },
   "outputs": [],
   "source": [
    "def get_unet_model(activation, learning_rate, optimizer, input_channel_num=3, out_ch=3, start_ch=64, depth=4, \n",
    "                   inc_rate=2., dropout=0.5, batchnorm=False, maxpool=True, upconv=True, residual=False):\n",
    "    def _conv_block(m, dim, acti, bn, res, do=0):\n",
    "        n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
    "        n = BatchNormalization()(n) if bn else n\n",
    "        n = Dropout(do)(n) if do else n\n",
    "        n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
    "        n = BatchNormalization()(n) if bn else n\n",
    "\n",
    "        return Concatenate()([m, n]) if res else n\n",
    "\n",
    "    def _level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
    "        if depth > 0:\n",
    "            n = _conv_block(m, dim, acti, bn, res)\n",
    "            m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
    "            m = _level_block(m, int(inc * dim), depth - 1, inc, acti, do, bn, mp, up, res)\n",
    "            if up:\n",
    "                m = UpSampling2D()(m)\n",
    "                m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
    "            else:\n",
    "                m = Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)\n",
    "            n = Concatenate()([n, m])\n",
    "            m = _conv_block(n, dim, acti, bn, res)\n",
    "        else:\n",
    "            m = _conv_block(m, dim, acti, bn, res, do)\n",
    "\n",
    "        return m\n",
    "\n",
    "    i = Input(shape=(None, None, input_channel_num))\n",
    "    o = _level_block(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)\n",
    "    o = Conv2D(out_ch, 1)(o)\n",
    "    model = Model(inputs=i, outputs=o)\n",
    "    \n",
    "    model.compile(optimizer=optimizer(lr=learning_rate), loss=\"mae\", metrics=[PSNR])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-5*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "# this is our parameter grid\n",
    "param_grid = {\n",
    "    'batch_size': [4, 8, 16, 24],\n",
    "    'learning_rate': (1e-4, 1e-1, 'log-uniform'),\n",
    "    'activation' : ['relu', 'tanh', 'sigmoid'],\n",
    "    'optimizer': [SGD, RMSprop, Adagrad, Adadelta, Adam]\n",
    "}\n",
    "model = KerasRegressor(build_fn=get_unet_model, epochs=20)\n",
    "# set up our optimiser to find the best params in 30 searches\n",
    "bayes = BayesSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    random_state=1234,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "bayes.fit(x, y)\n",
    "\n",
    "print('Best params achieve a test score of', bayes.score(x, y), ':')\n",
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "09UH2-4DJYwZ",
    "outputId": "36b190f2-07d6-4ebd-d834-f4c7d5c27600"
   },
   "outputs": [],
   "source": [
    "# model = KerasRegressor(build_fn=get_unet_model, epochs=20, batch_size=8)\n",
    "# model.fit(x=x, y=y)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Clean_target_training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
